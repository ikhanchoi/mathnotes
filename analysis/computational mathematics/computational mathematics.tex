\documentclass{../../large}
\usepackage{../../ikhanchoi}


\begin{document}
\title{Computational Mathematics}
\author{Ikhan Choi}
\maketitle
\tableofcontents
\part{Numerical analysis}

\chapter{Ordinary differential equations}
\section{Polynomial interpolations}
\section{Differentiation and integration}
\section{Runge-Kutta methods}
\section{Multi-step methods}




\chapter{Numerical linear algebra}


%Leonidas Mindrinos Otmar Scherzer
\chapter{Finite difference methods}
\section{Elliptic equations}
\begin{prb}[1D Poisson equation]
Consider the following boundary value problem:
\[\left\{\begin{alignedat}{2}
-u''(x)&=f(x),&\quad&\text{ in }(0,1),\\
u(0)=u(1)&=0.&&
\end{alignedat}\right.\]
We discretize it by $(u_j)_{j=0}^N$ such that $hN=1$ and
\[\left\{\begin{alignedat}{2}
-\frac{u_{j+1}-2u_j+u_{j-1}}{h^2}&=f_j,&\quad&\text{ for }j=1,\cdots,N-1,\\
u_0=u_N&=0.&&
\end{alignedat}\right.\]
\[\frac1{h^2}\mat{2&-1&&0\\-1&2&\ddots&\\&\ddots&\ddots&-1\\0&&-1&2}\mat{u_1\\u_2\\\vdots\\u_{N-1}}=\mat{f_1\\f_2\\\vdots\\f_{N-1}}\]
\end{prb}
eigenvalue problems

\section{Parabolic equations}


\section{Hyperbolic equations}
CFD

\chapter{Finite element methods}



\subsection{Approximation of Banach spaces}
We follow closely Temam for the abstract error analysis.
The word ``approximation'' in here can be replaced into ``discretization''.

\begin{defn}[Approximation]
Let $X$ be a Banach space.
An \emph{approximation} of $X$ is an indexed family $X_h$ of finite-dimensional normed spaces, with a \emph{prolongation operator} $p_h\in B(X_h,X)$ and a \emph{restriction operator} $r_h:X\to X_h)$.
The operator $p_hr_h:X\to X$ is called the \emph{truncation operator}.
\begin{cd}
X\dar[->>,swap]{r_h} \\ X_h\uar[bend right,swap]{p_h}
\end{cd}
\end{defn}

\begin{defn}[Errors]
Let $X_h$ be an approximation of a Banach space $X$.
For $x\in X$ and $x_h\in X_h$, the quantities $E(x_h,x):=\|p_hx_h-x\|$ and $DE(x_h,x):=\|x_h-r_hx\|$ are called the \emph{error} and the \emph{discrete error} between $x$ and $x_h$.
The quantity $TE(x):=\|x-p_hr_hx\|$ is called the \emph{truncation error}.
\end{defn}

\begin{defn}[Stable and convergent approximations]
We say an approximation $X_h$ is
\begin{parts}
\item \emph{stable} if $\|p_h\|+\|r_h\|\lesssim1$,
\item \emph{convergent} if $\|p_hr_hx-x\|\to0$ for each $x\in X$.
\end{parts}
\end{defn}

\begin{lem}
Let $X_h$ be an approximation of a Banach space $X$.
If $X_h$ is stable and convergent, then for each net $x_h\in X_h$ the discrete convergence implies the strong convergence.
\end{lem}
\begin{pf}
We have for each $x\in X$ that
\[DE=\|r_h\|\cdot E\quad\text{ and }\quad E=\|p_h\|\cdot DE+TE.\qedhere\]
\end{pf}

\begin{lem}
Let $X_h$ be an approximation of a Banach space $X$.
If $\|p_hx\|\sim\|x\|$, then the stability of $X_h$ follows from the convergence of $X_h$.
\end{lem}
\begin{pf}
It is by the uniform boundedness principle:
\[\|r_hx\|\lesssim\|p_hr_hx-x\|+\|x\|.\]
\end{pf}
In most cases we have $\|p_hx\|=\|x\|$, so for an approximation it is enough to verify the truncation error converges to zero.



\subsection{Approxiamation of problems}

A \emph{well-posed problem} is an operator $L:\cX\to\cY$ such that there is a continuous operator $L^{-1}:Y\to X$ satisfying $LL^{-1}=\id_Y$, where $X\subset\cX$ and $Y\subset\cY$ are embeddings.
Say, consider the spaces $\cX$ and $\cY$ as space of distributions.
We will always assume $L:X\to Y$ is a right invertible(i.e. well-posed) linear operator between Banach spaces.

\begin{defn}[Approximation]
Let $L$ be a well-posed linear problem.
An \emph{approximation} of $L$ is an indexed family $L_h\in L(X_h,Y_h)$ of invertible linear operators, where $X_h$ and $Y_h$ are stable and convergent approximations of $X$ and $Y$.
\end{defn}
We also do not need to assume in fact the stability of $r_h$.
The approximation $X_h$ of $X$ is where we should take subtly, and the art of numerical analysis begins with the choice of $X_h$.
The following diagram does not commute, but \emph{approximately} commute.
\begin{cd}
X \dar[dashed,bend right,swap]{r_h}\rar{L} & Y \dar{r_h} \\
X_h \uar[dashed,bend right,swap]{p_h}\rar{L_h} & Y_h
\end{cd}

\begin{defn}
Let $L_h$ be an approximation of a well-posed linear problem $L$.
We say $L_h$ is
\begin{parts}
\item \emph{consistent} if $CE=\|r_hLx-L_hr_hx\|\to0$ for each $x$,
\item \emph{stable} if $\|L_h^{-1}\|\lesssim1$,
\item \emph{convergent} if $DE=\|L_h^{-1}r_hLx-r_hx\|\to0$ for each $x$.
\end{parts}
\end{defn}

\begin{thm}[Lax equivalence]
Let $L_h$ be an approximation of a well-posed linear problem $L$.
If $L_h$ is consistent, then it is stable if and only if it is convergent.
\end{thm}
\begin{pf}
($\Rightarrow$)
It is clear from
\[DE=\|x_h-r_hx\|\le\|L_h^{-1}\|\|r_hLx-L_hr_hx\|=\|L_h^{-1}\|\cdot CE.\]

($\Leftarrow$)
If we show for the net of operators $p_hL_h^{-1}r_h:Y\to X$ that $p_hL_h^{-1}r_hy$ is bounded in $X$ for each $y\in Y$, then by the uniform boundedness principle the operators $p_hL_h^{-1}r_h$ is uniformly bounded, and we obtain the stability from
\[\|L_h^{-1}\|=\|r_hp_hL_h^{-1}r_hp_h\|\le\|r_h\|\|p_hL_h^{-1}r_h\|\|p_h\|.\]

Since $L$ is surjective by the well-posedness, there is $x\in X$ such that $Lx=y$.
With this $x$ we have
\[\|p_hL_h^{-1}r_hy-x\|\le\|p_h\|\cdot DE+TE\to0,\]
so we are done. 

\end{pf}




\subsection{Numerical analyses}
For a numerical approximation, we can consider three analyses:
\begin{enumerate}
	\item Consistency analysis,
	\item Statbility analysis,
	\item Error analysis.
\end{enumerate}
Note that we have $DE\le\|L_h^{-1}\|\cdot CE$.
If we have the estimate for the rate of the consistency error from the consistency analysis, and also if we have the bound of $\|L_h^{-1}\|$ in the stability analysis, we can easily obtian an \emph{error estimate}.
In this regard, the main difficulty is the former two.


\subsubsection*{Consistency analysis}
Usually the Taylor's theorem is used in finite difference schemes.


\subsubsection*{Stability analysis}
For the bound of $\|L_h^{-1}\|$, we have to make a \emph{stability estimate}
\[\|x_h\|\lesssim\|L_hx_h\|.\]

We have some notes about uniqueness and existence: the injectivity of $L_h^{-1}$ clearly follows from the above estimate, and the surjectivity is deduced thanks to the finite-dimensional nature of $X_h$ and $Y_h$ when their dimensions coincide.

\subsubsection*{Error analysis}
In the Ritz-Galerkin approximation the discrete solution operator $p_hL_h^{-1}r_hL$ can be directly shown to be an orthogonal projection called the \emph{Ritz projection}, which deduces an \emph{a priori} convergence result before justifying proving consistency and stability.




\subsection{Applications}
\begin{ex}
Consider
\[\left\{\begin{alignedat}{2}
u'(x)-u(x)&=f(x) &\qquad&\text{ in }x\in(0,1),\\
u(0)&=c. &&
\end{alignedat}\right.\]
Let $X:=C^1([0,1])$, $Y:=C([0,1])\times\R$, and $Au(x):=(u'(x)-u(x),u(0))$.
Then it is well-posed since there is $E:Y\to X$ defined by
\[E(f,c)(x):=c+\int_0^xe^{-y}f(y)\,dy\]
satisfies
\end{ex}

\begin{ex}
Consider
\[\left\{\begin{alignedat}{2}
-\Delta u(x)&=f(x) &\qquad&\text{ in }x\in(0,1)^2,\\
u(x)&=0 &&\text{ on }x\in\partial(0,1)^2.
\end{alignedat}\right.\]
Let $X=$, $Y=$, $Au$
\end{ex}

\begin{ex}
Consider
\[\left\{\begin{alignedat}{2}
\partial u(t,x)&=\Delta u(t,x) &\qquad&\text{ in }(t,x)\in(0,\infty)\times(0,1),\\
u(0,x)&=f(x) &&\text{ on }x\in[0,1],\\
u(t,0)&=0 &&\text{ on }t\in[0,\infty),\\
u(t,1)&=0 &&\text{ on }t\in[0,\infty),\\
\end{alignedat}\right.\]
Let $X=$, $Y=$, $Au$
\end{ex}


$u_j^n$, $t=t_0+nk$, $x=x_0+jh$




\chapter{Optimization}
\section{Convex optimization}
\section{Optimal control}
\section{Operations research}
theory of decision making
\section{Mathematical programming}


\chapter{Monte Carlo method}
stochastic



\part{Information theory}
\chapter{Communication theory}
shannon's theory
\chapter{Coding theory}
\chapter{Cryptography}





\part{Mathematical statistics}
% regression, discrete data, experiment design, bayes, multivariate, sequential, survival
% non-parametric, time series
\chapter{Statistical models}
\chapter{Statistical inference}
estimation, testing hypothesis, ranking, selection
\section{Parametric inference}
\section{Non-parametric inference}


\chapter{}




\end{document}