\documentclass{../../../small}
\usepackage{../../../ikhanchoi}

\DeclareMathOperator{\Int}{Int}

\newcommand{\Gr}{\mathrm{Gr}}

\begin{document}
\title{Integrable Systems}
\author{Ikhan Choi\\Lectured by Ralph Willox\\University of Tokyo, Autumn 2023}
\maketitle
\tableofcontents

\newpage
\section{Day 1: October 9}

Every linear system will be considered to be solvable.

Two mainstreams: 1+1-dimensional, 2+1-dimensional (Russia, Japan)

Sato theory

Hirota: relation to discrete systems

\subsection*{KdV equation}
Consider $u=u(x,t)\in C^\infty(\R^2)$ which is Schwarz in the sense that $\lim_{x\to\pm\infty}u_{px,qt}=0$ for all $p,q$.
The KdV equation is
\[u_t+u_{3x}+6uu_x=0.\]
One of the form of the discrete KdV equation(dKdv) by Hirota is
\[\frac1{u_{n+1}^{t+1}}-\frac1{u_n^t}=\delta(u_n^{t+1}-u_{n+1}^t)\]
for $u:\Z^2\to\C$ and $\delta\in\C\setminus\{0\}$.

There is a continuous limit(?) deduces KdV from dKdV.
Using the Darboux transformation(?) we can construct dKdV from KdV, preserving some additive formulas(such as sine and cosine?), but it seems to be impossible to reconstruct by numberical schemes.

There is an ultradiscrete limit which derives udKdV equation.
($\delta=e^{-1/\e}$ and $u=e^{U/\e}$ with $\e\to0$.
\[\e\log(\frac1{u_{j+1}^{t+1}}+\delta u_{j+1}^t)=\e\log(\delta u_j^{t+1}+\frac1{u_j^t})\]
\[\max[-U_{j+1}^{t+1},U_{j+1}^t-1]=\max[U_j^{t+1}-1,-U_j^t].\]
Toda equation
\[(\Theta_j)_{xy}=e^{-\Theta_{j+1}}-2e^{-2\Theta_j}+e^{-\Theta_{j-1}}.\]
)
The multiplication and addition are transformed to the addition and $\max$(or $\min$) respectively.
One of the form of the ultradiscrete KdV equation(udKdV) is
\[U_n^{t+1}=\min\left[1-U_n^t,\sum_{k=-\infty}^{n-1}(U_k^t-U_k^{t+1})\right].\]
If $U_n^0\in\{0,1\}$ for all $n$, then it is the Box and Ball system.

\subsection*{Properties that must be satisfied by integrable systems}

\begin{enumerate}
\item There are special solutions descrbing interactions of $\forall N$-soliton.
\item There exists a corresponding Hirota bilinear form.
\item There exists a Lax pair. (for udKdV, there are four equations for the Lax ``pair'', so it is not a Lax pair rigorously)
\item There are infinitely many invariants. (for udKdV there are some combinatoral arguments with Young tableaux) (for dKdV it is an open problem. For example, $\prod_ju_j^t$ is conserved, but only three? or four quantities are known.)
\item There are infinitely many symmetries. (Nobody has shown that there is no conserved quantity which does not come from a symmetry in the sense of Noether's theorem)
\item There is a Hamiltonian structure: the continuous KdV only have this property. (dKdV and udKdV admit Poisson structures)
\end{enumerate}

\subsection*{$N$-soliton of KdV}

Let $u(x,t)=U(x-ct)=U(\zeta)\not\equiv0$ with $c>0$ as an ansatz.
Then, $u_t=-cU'$ and $u_x=U'$ so that the KdV becomes
\[-cU'=U'''+6UU'.\]
This process generating an ODE is called a reduction.
We can integrate the equation to get
\[-cU=U''+3U^2+a\]
and
\[-\frac c2U^2=\frac12(U')^2+U^3+aU+b.\]
Thus we have a general solution of $U$ with the Weierstrass $\wp$ such that $(\wp')^2=4\wp^3-g_2\wp-g_3$ that
\[u=\frac c6-2\wp(\zeta),\]
where 
\[g_2=a+\frac{c^2}12,\qquad g_3=-(\frac{c^3}{216}+\frac{ac}{12}+\frac bc).\]
The general means that every transmitting solution has this form.
The Weierstrass $\sigma$ function satisfies $\wp(\zeta)=-\frac d{d\zeta^2}\log\sigma(\zeta)$.
Then we have
\[u(x,t)=2\partial_\zeta^2\log[\sigma(\zeta)e^{\frac c{24}\zeta^2}].\]
The function $\sigma(\zeta)e^{\frac c{24}\zeta^2}$ is a prototype of $\tau$ functions of Hirota and Sato.
If $a=b=0$, then the pole of $\sigma$ disappears in the sense that
\[u(x,t)=2\partial_x^2\log[1+e^{\theta(x,t)}],\qquad\theta(x,t)=k(x-k^2t+\delta),\quad k,\delta\in\R.\]
Here $c=k^2>0$.
This solution is the 1-soliton parametrized by $k$ and $\delta$.

\subsection*{Hirota bilinear form}
If we define $\tau:=1+e^\theta$ so that $u=2\partial_x^2\log\tau$, then
\[u_t+u_{3x}+uu_x=(2\log\tau)_{xxt}+(u_{2x}+3u^2)_x=2\left[\frac{\tau_{xt}\tau-\tau_x\tau_t+\tau_{4x}\tau-4\tau_{3x}\tau_x+3\tau_{2x}^2}{\tau^2}\right]_x.\]
One of the miracles is the denominator is $\tau^2$, not $\tau^3$.
For the case $\tau=1+e^{\theta(x,t)}$ we have the numerator zero:
\[\tau_{xt}\tau-\tau_x\tau_t+\tau_{4x}\tau-4\tau_{3x}\tau_x+3\tau_{2x}^2=0.\]

Define a differential operator $\cD$ such that
\[\cD_x^p\cD_t^qf\cdot g:=\partial_\e^p\partial_\eta^qf(x+\e,t+\eta)g(x-\e,t-\eta)|_{\e=\eta=0}.\]
For example,
\begin{gather*}
\cD_x^pf\cdot g=\sum_{n=0}^p{p\choose n}(-1)^{p-n}f_{nx}g_{(p-n)x},\\
\cD_x\cD_tf\cdot g=f_{xt}g-f_xg_t-f_tg_x+fg_{xt},\\
\cD_x^4f\cdot g=f_{4x}g-4f_{3x}g_x+6f_{2x}g_{2x}-4f_xg_{3x}+fg_{4x}.
\end{gather*}
In fact, $(\cD_x\cD_t+\cD_x^4)\tau\cdot\tau=0$.

We have some properties
\begin{parts}
\item $\cD_x^p\cD_t^qf\cdot g=(-1)^{p+q}\cD_x^p\cD_t^qg\cdot f$
\item $\cD_x^p\cD_t^q(\lambda_1f+\lambda_2f_2)\cdot(\mu_1g_1+\mu_2g_2)=\cdots$ (bilinearity)
\item $\cD_x^p\cD_t^qe^{k_1x+\omega_1t}\cdot e^{k_2x\omega_2k}=(k_1-k_2)^p(\omega_1-\omega_2)^qe^{(k_1+k_2)x+(\omega_1+\omega_2)t}$.
\end{parts}
We can compute
\[(\cD_x\cD_t+\cD_x^4)(1+e^\theta)\cdot(1+e^\theta)=-2k^4e^\theta+2k^4e^\theta=0.\]

Let $u=2\partial_x^2\log\tau_2$, where
\[\tau_2:=1+e^{\theta_1}+e^{\theta_2}+A_{12}e^{\theta_1+\theta_2},\]
$\theta_j=k_j(x-k_j^2t+\delta_j)$, $A_{12}=((k_1-k_2)/(k_1+k_2))^2\notin\{0,\infty\}$.
Let $k_1>k_2>0$.
After interaction, the 1-solitons $u\sim2\partial_x^2\log(1+e^{\theta_1})$ and $u\sim2\partial_x^2\log(1+e^{\theta_2})$ is slightly translated with $\delta_1'=\delta_1+\frac1{k_1}\log A_{12}$ and $\delta_2'=\delta_2-\frac1{k_2}\log A_{12}$.
The fastest particle propagates because $\delta_1'<\delta_1$.

For 3-soliton,
\[\tau_3=1+e^{\theta_1}+e^{\theta_2}+e^{\theta_3}+A_{12}e^{\theta_1+\theta_2}+A_{13}e^{\theta_1+\theta_3}+A_{23}e^{\theta_2+\theta_3}+A_{12}A_{13}A_{23}e^{\theta_1+\theta_2+\theta_3}\]
with $A_{ij}=((k_i-k_j)/(k_i+k_j))^2$.

Then, $\delta_1\to\delta_1'=\delta_1+\frac1{k_1}(\log A_{12}+\log A_{13})$.
The three-body problem is chaotic and not integrable, so it is not surprising that integrable systems do not include three-body interactions.

The modified KdV(mKdV) equation is
\[V_t+V_{3x}-6V^2V_x=0.\]
If we put $u=\pm V_x-V^2$, then
\[u_t+u_{3x}+6uu_x=(\pm\partial_x-2V)(V_t+V_{3x}-6V^2V_x).\]
It implies that if we have a solution $V$ of mKdV, then we can construct a pair of solutions of KdV.
It is called the Miura transformation.
The inverse transformation is also abtained by solving the ODE: if we let $V=\partial_x\log\psi$, then
\[V_x-V^2=\psi^{-1}\psi_{xx}.\]
The Miura transformation is very close to the Lax pair.

The nonlinear Schr\"odinger equation, which describes photon soliton in optical LAN, is
\[i\psi_t+\psi_{2x}+\sigma|\psi|^2\psi=0.\]
The sine-Gordon equation is
\[\omega_{xt}=\sin\omega,\]
whose discrete version is virtually equivalent to the one of mKdV.

\newpage
\section{Day 2: October 16}
\subsection*{Lax pair}
For a function $u$, define operators
\[L(u):=\partial_x^2+u,\qquad M(u):=-4\partial_x^3-3(u\partial_x+\partial_xu)=-4\partial_x^3-6u\partial_x-3u_x.\]
If $u$ satisfies the continuous KdV $u_t+u_{3x}+6uu_x=0$, then we have as operators
\[L_t-[M,L]=u_t+u_{3x}+6uu_x=0,\]
where $L_t$ is just the multiplication operator by $u_t$ as the differential operator $\partial_x^2$ vanishes by $\partial_t$.

For any function $u$ and $\lambda\in\C$, consider the following ``Lax pair equation''
\begin{align*}
&L(u)\psi=\lambda^2\psi\\
&\psi_t=M(u)\psi.
\end{align*}
It is important to note that this equation is linear.
If a non-trivial (for all $t$) $\psi$ satisfies the above equation for some $\lambda$, then the computation
\[((\lambda^2-u)\psi)_t=(M(u)\psi)_{xx}\quad\Leftrightarrow\quad(u_t+u_{3x}+6uu_x)\psi=0\]
implies $u$ satisfies KdV.
In other words, by solving the ``Lax pair equation'', we obtain the solutions of KdV equation.

A reference: Peter Lax (1968) ``Integrals of nonlinear equations of evolution and solitary waves'' Comm Pure Applied Math 21, 467-490.

We can see some similar structure to $L_t=[M,L]$ in seversal situations, especially in physics.
Recall the Hamilton equation $\dot f=\{f,H\}$ in the Hamiltonian mechanics.
Also in quantum mechanics if we let $U(t):=e^{-\frac i\hbar Ht}$, then
\[A_t=(A(t))_t=(U(t)^*AU(t))_t|_{t=0}=-\frac i\hbar[A,H]\]

\[*\qquad*\qquad*\]
\smallskip

Every transpose of operator will respect the \emph{real} inner product
\[\<A,B\>:=\int_\R A(x)B(x)\,dx.\]

Let $M(t)$ be such that $M(t)+M(t)^t=0$ and let $L(0)$ be some operator, like $\partial_x^2+u_0$.
If we define $U(t)$ such that $U(0)=\id$ and $U_t(t)=M(t)U(t)$ so that
\[U(t)=\id+\int_0^tM(u(s))U(s)\,ds,\]
whence $(U^tU)_t=(UU^t)_t=0$ so that the unitarity of $U(0)$ implies the unitarity of $U(t)$.
($U(t)$ commutes with $\partial_x^2$?)
For this $U(t)$ defined by $M(t)$, if we define $L(t):=U(t)L(0)U(t)^t$, then we automatically have $L_t(t)=[M(t),L(t)]$.

For example, let
\[M_1(t)\equiv-\partial_x,\qquad L(0):=\partial_x^2+u_0.\]
Then, $L(t)=\partial_x^2+u(t)$, where $u(t)$ is the solution of $u(0)=u_0$ and
\[0=L_t(t)-[M_1(t),L(t)]=u_t+u_x.\]

For another example, for any function $u(t)$, let
\[M_3(t):=-4[\partial_x^3+\frac34(u(t)\partial_x+\partial_xu(t))],\qquad L(0):=\partial_x^2+u_0.\]
Then, similarly, if we consider $U(t)$ we obtain $L(t)=\partial_x^2+u(t)$, where $u$ satisfies the KdV equation because
\[0=L_t(t)-[M_3(t),L(t)]=u_t+u_{3x}+6uu_x.\]
More precisely, we can show that if $u$ satisfies KdV, then we can show
\[\frac d{dt}[U(t)^*(\partial_x^2+u(t,x))U(t)]=0.\]


Under the condition that $M(t)$ is skew symmetric, once we have a non-trivial solution for the first ``Lax pair equation'' $L(0)\psi_0=\lambda^2\psi_0$ only at $t=0$, then we can deduce the solution $\psi(t)$ of $\psi_t(t)=M(t)\psi(t)$ is always non-trivial for all $t>0$ because $\psi(t)$ is given by the unitary transformation of $\psi_0$.
It implies that the existence of $\psi_0$ gives the existence of $u(t)$!

An exmplae of this kind of linearization: the logistic map $x_{n+1}=4x_n(1-x_n)$ with $[0,1]\to[0,1]:x_n\mapsto x_{n+1}$ is a solvable chaos in which the solution is given by $x_n=\sin^2\theta_n$, where $\theta_{n+1}=2\theta_n$.
The $\theta_{n+1}=2\theta_n$ is linear chaos.

\[*\qquad*\qquad*\]
\smallskip

Let $M_1(t):\equiv-\partial_x$, $M_3(t):=-4\partial_x^3-6u\partial_x-3u_x$, and $L(0)=\partial_x^2+u_0$.
We want to define $U_{13}(t_1,t_3)$ such that
\[U_{13}(0,0)=\id,\qquad (U_{13})_{t_1}=M_1(t)U_{13}(t),\qquad (U_{13})_{t_3}=M_3(t)U_{13}(t).\]
For $U_{13}$ to exist, we need to satisfy the consistency
\[(M_1)_{t_3}-(M_3)_{t_1}=[M_3,M_1],\]
implying
\[2(u_{t_1}+u_x)\partial_x+(u_{t_1}+u_x)_x=0.\]

KdV hierarchy
$L:=\partial_x^2+u(x,t_1,t_3,t_5,\cdots)$,
\[L_{t_j}=M_jL-LM_j\quad\Leftrightarrow\quad u_{t_j}+u_{jx}+\cdots=0,\]
\[u_{t_1}+u_x=0,\]
\[u_{t_3}+u_{3x}+6uu_x=0,\]
\[u_{t_5}+u_{5x}+(10uu_{2x}+5u_x^2+10u^3)_x=0,\cdots\]



\newpage
\section{Day 3: October 23}

Every $u$ is supposed to be in Schwartz class.
If $u$ is a solution of the KdV
\[u_t=u_{3x}+6uu_x,\]
then
\[\int u\,dx,\qquad\int\frac12u^2\,dx,\qquad\int(u^3-\frac12u_x^2)\,dx\]
are invariants as time flows, called the mass, momentum, and energy, respectively.
In fact, there are infinitely many invariants.
They follow not from the symmetry of KdV equation, but from the symmetry of action.

The symmetry of KdV: If $u(x,t)$ is a solution of KdV, then
\begin{enumerate}
\item so is $u(x+\e,t)$,
\item so is $u(x,t+\e)$,
\item so is $\lambda^2u(\lambda x,\lambda^3t)$, (scaling)
\item so is $u(x-6\e t,t)+\e\notin\cS$. (Galilean boost)
\end{enumerate}
For example, there is no corresponding invariant to the scaling symmetry of KdV, but Galilean boost is related to an invariant.
These (local) symmetries come from the one-parameter transformations
\begin{enumerate}
\item $X=x+\e$, $T=t$, $U=u$,
\item $X=x$, $T=t+\e$, $U=u$,
\item $X=e^{-\e}x$, $T=e^{-3\e}t$, $U=e^{2\e}u$,
\item $X=x+6\e t$, $T=t$, $U=u+\e$.
\end{enumerate}
They are invertible in sufficiently small $\e$.
For $u$ satisfying KdV, we want for
\[U((X,T)^{-1}(x,t;\e),u((X,T)^{-1}(x,t;\e));\e)\]
to satisfy KdV.
Differentiating along $\e$ at $\e=0$, define
\begin{align*}
\sigma:&=\frac{\partial U}{\partial(x,t)}\frac{\partial(X,T)^{-1}}{\partial\e}+\frac{\partial U}{\partial u}\frac{\partial u}{\partial (x,t)}\frac{\partial(X,T)^{-1}}{\partial\e}\\
&=(U_x,U_t)\cdot\frac{\partial(X,T)^{-1}}{\partial\e}+U_u(u_x,u_t)\cdot\frac{\partial(X,T)^{-1}}{\partial\e}\\
&=(U_x+U_uu_x,\ U_t+U_uu_t)\cdot(-X_\e,-T_\e)\ (?)\\
&=-(U_x+U_uu_x)X_\e-(U_t+U_uu_t)T_\e
\end{align*}

Let $K(u):=-(u_{3x}+6uu_x)$, that is, $K$ is a differential polynomial.
Then, for multi-indices $J=(j_t,j_x)$, by considering Fr\'echet derivative $K'$ of $K$, we have
\begin{align*}
u_t+\e\sigma_t+o(\e)
&=K(u)+\e K'(u)[\sigma]+o(\e)\\
&=K(u)+\e\sum_J\frac{\partial K}{\partial u_J}\sigma_J+o(\e)\\
&=K(u)+\e(\sigma_{3x}+6u\sigma_x+6u_x\sigma)+o(\e).
\end{align*}
We say $\sigma=\sigma(t,u)$ is a \emph{symmetry} of $K$ if it satisfies
\[\sigma(t,u)_t=K'(u)[\sigma(t,u)]\quad\Leftrightarrow\quad\frac{\partial\sigma}{\partial t}(t,u)+\sigma'(t,u)[u_t]=K'(u)[\sigma(t,u)]\quad\Leftrightarrow\quad\frac{\partial\sigma}{\partial t}=K'[\sigma]-\sigma'[K].\]
We use the notation $\sigma'=\partial\sigma/\partial u$.

Here is the fifth symmetry
\[\sigma(u)=u_{5x}+10uu_{3x}+20u_xu_{2x}+30u^2u_x.\]
It satisfies $\partial\sigma/\partial t=0$ and $\sigma'[K]=K'[\sigma]$.


\bigskip
Let $\rho$ be a differential polynomial with respect only to $x$.
If we let $I(u,t):=\int\rho(u,t)\,dx$ or $I(u):=\int\rho(u)\,dx$, then
\[\frac{dI}{dt}=\int(\frac{\partial\rho}{\partial t}+\rho'(u)[u_t])\,dx=\frac{\partial I}{\partial t}+\int\rho'(u)[u_t]\,dx.\]
If $\partial\rho/\partial t=0$, then we try to compute the gradient of $I$ as in the calculus of variations,
\[I'(u)[v]=\<\rho'(u)^T[1],v\>_{L^2(\R_x)}=:\<(\grad I)(u),v\>_{L^2(\R_x)}.\]
We can apply the integration by parts to compute the transpose.
For examples,
\begin{enumerate}
\item If $\rho(u)=u$, then $\grad I=1$.
\item If $\rho(u)=u^2$, then $\grad I=2u$.
\item If $\rho(u)=u^3-\frac12u_x^2$, then $\grad I=u_{2x}+3u^2$.
\end{enumerate}

Olver



\newpage
\section{Day 4: October 30}

Linear functionals in classical field theory, like action(time-space $dt\,dx$) or invariants(only spatial space $dx$), are defined by integrating a differential polynomial of a field.
Let $\cD_x:=\cS(\R)$, $\cD_t:=C^\infty([0,\infty))$, and $\cD_{x,t}:=C^\infty([0,\infty),\cS(\R))$.
For a linear functional $I:\cD_{x,t}\to\cD_t$, defined by the spatial integration a differential polynomial $\rho:\cD_{x,t}\to\cD_{x,t}$, its spatial gradient $\gamma=\grad I$ is given by a differential polynomial $\gamma:=\rho'(\cdot)^T[1]:\cD_{x,t}\to\cD_{x,t}$ such that
\[I'(u)[v]=\<\gamma(u),v\>_{L^2(\R)},\qquad u\in\cD_{x,t},\ v\in\cD_x.\]
We can recognize this by applying the chain rule on
\[I:\cD_{x,t}\xrightarrow{\rho}\cD_{x,t}\xrightarrow{\int_\R}\cD_t.\]
Note that $\rho'(u):\cD_x\to\cD_{x,t}$ and $\rho'(u)^T:\cD_x\to\cD_{x,t}$ and $\rho'(u)^T[1]\in\cD_{x,t}$.
Then, the spatial Fr\'echet derivative $\gamma'(u)$ of a non-linear operator $\gamma:\cD_{x,t}\to\cD_{x,t}$ at $u$ also can be viewed as an operator
\[\gamma'(u):=\sum_J\frac{\partial\gamma}{\partial u_J}(u)\partial_J.\]
\begin{prop}
Let $\gamma$ be the gradient of a linear functional $I$, defined by $I(u):=\int\rho(u)\,dx$.
\begin{parts}
\item $\gamma'(u)$ is a symmetric operator.
\item Every differential polynomial $g$ whose Fr\'echet derivative $g'(u)$ defines a symmetric operator is the gradient of
\[I(u):=\int u\int_0^1g(\lambda u)\,d\lambda\,dx.\]
\item 
If $\frac{\partial g}{\partial t}+g'[K]+K'^T[g]=0$ as differential polynomials, and if $K(0)=0$, then $I(u)=\int u\int_0^1g(\lambda u)\,d\lambda\,dx$ is an invariant of $u_t=K(u)$.
\end{parts}
\end{prop}
\begin{pf}

(b)
\begin{align*}
I'(u)[v]
&=\int v\int_0^1g(\lambda u)\,d\lambda\,dx
+\int u\int_0^1\left.\sum_J\frac{\partial g}{\partial u_J}\partial_J\right|_{u\to\lambda u}\lambda v\,dx\\
&=\left<\int_0^1(g(\lambda u)+\lambda g'(u)^T|_{\lambda u}[u])\,d\lambda,v\right>\\
&=\left<\int_0^1\frac d{d\lambda}(\lambda g(\lambda u))\,d\lambda,v\right>\\
&=\<g(u),v\>.
\end{align*}

(c)
\begin{align*}
\left(\frac{dI}{dt}\right)'[v]
&=\left(\frac{\partial I}{\partial t}\right)'[v]
+\<\gamma'(u)[v],K(u)\>+\<\gamma(u),K'(u)[v]\>\\
&=\<\frac{\partial\gamma}{\partial t},v\>+\<\gamma'(u)[K(u)],v\>+\<K'(u)^T[\gamma(u)],v\>
\end{align*}
\end{pf}

\begin{ex}[Boussinesq equation]
$u_{2t}+u_{4x}+(3u^2)_{2x}=0$ can be rewritten as
\[(u,v)_t=(v,-(u_{2x}+3u^2)_{2x})=:K(u,v)\]
if $v:=u_t$.
\end{ex}



\newpage
\section{Day 5: November 6}


\begin{lem}
Let $p,q$ be differential polynomials.
For a multi-index $J$, there is a vector field $V$ such that $p_Jq=(-1)^{|J|}pq_J+\div V$.
For example,
\[p_xq=-pq_x+\div(pq,0),\qquad p_{xt}q=pq_{xt}+\div(p_tq,-pq_x).\]
\end{lem}
\begin{pf}
We can prove by induction.
\end{pf}



For a differential polynomial $L$,
\[L'(u)[v]=\sum_Jv_J\frac{\partial L}{\partial u_J}=\sum_J(-1){|J|}\left(\frac{\partial L}{\partial u_J}\right)_Jv+\div V=v(L'(u)^T[1])+\div V.\]
Therefore, the Euler-Lagrangian equation for the Lagrangian $L$ is $L'(u)^T[1]=0$.
For example, if we define a Lagrangian $L(u):=\frac12(u_t^2-c^2u_x^2)$, then
\begin{align*}
L'(u)&=u_t\partial_t-c^2u_x\partial_x\\
L'(u)^T&=-\partial_tu_t+c^2\partial_xu_x\\
L'(u)^T[1]&=-u_{tt}+c^2u_{xx}.
\end{align*}
Conversely, we can reconstruct $L$ from the EL equation using the formula in the part (b) of Proposition 4.1.~if $E'(u)[\cdot]=E'(u)^T[\cdot]$ for $u$ satisfying $E(u)=0$.

Is the KdV a Euler-Lagrange equation?
No, because if we let $E(u):=u_t+u_{3x}+6uu_x=0$, then
\[E'(u)=\partial_t+\partial_x^3+6u\partial_x+6u_x,\qquad E'(u)^T=-\partial_t-\partial_x^3-6u\partial_x\]
are different.
However, if we put $u=w_x$, then the potential KdV
\[\tilde E(w)=w_{xt}+x_{4x}+6w_xw_{2x}\]
is a Euler-Lagrange equation since
\[\tilde E'(w)=\partial_{xt}+\partial_{4x}+6w_x\partial_x^2+6w_{2x}\partial_x=\tilde E'(w)^T.\]
The Lagrangian can be determined by the following computation:
\begin{align*}
S(w)&=\iint w\int_0^1\tilde E(\lambda w)\,d\lambda\,dx\,dt\\
&=\iint w\int_0^1\tilde E(\lambda w_{xt}+\lambda w_{4x}+\lambda^26w_xw_{2x})\,d\lambda\,dx\,dt\\
&=\iint w(\frac12w_{xt}+\frac12w_{4x}+2w_xw_{2x})\,dx\,dt\\
&=\frac12\iint\left[((-w_xw_t)+(ww_t)_x)+((ww_{3x})_x-(w_xw_{2x})_x+w_{2x}^2))+(2(ww_x^2)_x-2w_x^3)\right]\,dx\,dt\\
&=\frac12\iint\left[-w_xw_t+w_{2x}^2-2w_x^3\right]\,dx\,dt,
\end{align*}
i.e.~we can define
\[L(w):=\frac12(w_{2x}^2-w_xw_t-w_x^3).\]
We can check
\[L'(w)^T[1]=w_{xt}+w_{4x}+6w_xw_{2x}.\]


For a symmetry $\sigma:\cD_{x,t}\to\cD_{x,t}$, i.e.~$(\partial\sigma/\partial t)(u)=K'(u)[\sigma(u)]-\sigma'(u)[K(u)]$, we have
\[S(u')-S(u)=\iint(L'(u)[\sigma]+\div(\xi L,\tau L))\,dx\,dt+o(1),\qquad \e\to0,\]
and
\[L'(w)[\sigma]+\div(\xi L,\tau L)=(\tau L-\frac12\sigma w_x)_t+(\xi L-\frac12\sigma w_t-3\sigma w_x^2+\sigma_xw_{2x}-\sigma w_{3x})_x+\sigma(w_{xt}+w_{4x}+6w_xw_{2x})\]
for potential KdV solution $w$ and potential KdV Lagrangian $L$.
Here
\[\rho(u):=\tau L-\frac12\sigma w_x,\]
then $\rho$ defines an invariant $I$.

\begin{ex}
(i)
If $\sigma=-w_x$, then

(ii)

(iii)

(iv)
\end{ex}


variation symmetry and divergence symmetry...
The power of Lagrangian is limited.

\begin{rmk}
The case (iii) in the above example gives an invariant of potential KdV, not of the original KdV.
The scaling symmetry is not the symmetry of action, so does not come from Noether's theorem.
Hamiltonian structrue of KdV(we will discuss in the next lecture) is not obtained from Lagrangian.
\end{rmk}



\newpage
\section{Day 6: November 13}

We say $u_t=K(u)$ admits a Poisson structure if there is $\Theta(u)$, which is
\begin{enumerate}[(i)]
\item a partial differential operators in $x$, where coefficients are differential polynomials of $u$, i.e.~$\Theta(u)=\sum_jc_j(u)\partial_x^j$,
\item satisfies $\Theta^T=-\Theta$,
\item such that for $\alpha,\beta,\gamma$ gradients ($\gamma'^T[\cdot]=\gamma'[\cdot]$),
\[\<\alpha,\Theta'[\Theta\gamma]\beta\>+\<\beta,\Theta'[\Theta\alpha]\gamma\>+\<\gamma,\Theta'[\Theta\beta]\alpha\>.\]
(For example of $\Theta'$, we have $\Theta(u)=\partial_x^2+u_x\partial_x+u$ if $\Theta'[\gamma]=\gamma_x\partial_x+\gamma$.)
\end{enumerate}
together with a differential polynomial $\gamma_H$ of $u$ which is a gradient such that $K(u)\equiv\Theta(u)\gamma_H$.
Define
\[H(u):=\int\int_0^1u(x)\gamma_H(\lambda u)(x)\,d\lambda\,dx,\qquad\{A,B\}_\Theta:=\<\gamma_A,\Theta\gamma_B\>,\]
where $A$ and $B$ are functionals.
Then, the bracket $\{,\}_\Theta$ satisfies the axioms of Poisson bracket except the Leibniz rule, i.e.~bilinearity, anti-commutativity, and the Jacobi identity.
We exclude the Leibnize rule because we do not consider products of functionals.
The Poisson structure is somtimes called the Hamiltonian structure in references.

We can check
\begin{align*}
\frac{dA}{dt}&=\frac{\partial A}{\partial t}+A'(u)[u_t]=\frac{\partial A}{\partial t}+\<\gamma_A,u_t\>\\
&=\frac{\partial A}{\partial t}+\<\gamma_A,K(u)\>=\frac{\partial A}{\partial t}+\<\gamma_A,\Theta\gamma_H\>=\frac{\partial A}{\partial t}+\{A,H\}_{\Theta}.
\end{align*}

Now we prove the Jacobi identity.
Note that $\{B,C\}_{\Theta}(u)=\<\gamma_B(u),\Theta(u)\gamma_C(u)\>$ is a functional of $u$.
If we define $\Theta'[v]\gamma_C=\Theta'(\gamma_C)[v]=:T_C[v]$, then
\begin{align*}
\{B,C\}_\Theta'[v]
&=\<\gamma_B'[v],\Theta\gamma_C\>+\<\gamma_B,\Theta'[v]\gamma_C\>+\<\gamma_B,\Theta\gamma_C'[v]\>\\
&=\<v,\gamma_B'[\Theta\gamma_C]\>+\<T_C^T[\gamma_B],v\>-\<\gamma'_C[\Theta\gamma_B],v\>\\
&=\<\gamma'_B[\Theta\gamma_C]+T_C^T[\gamma_B]-\gamma'_C[\Theta\gamma_B],v\>,
\end{align*}
so $\gamma_{\{B,C\}_\Theta}=\gamma'_B[\Theta\gamma_C]+T_C^T[\gamma_B]-\gamma'_C[\Theta\gamma_B]$.
Then,
\begin{align*}
\{A,\{B,C\}_\Theta\}_\Theta&+
\{B,\{C,A\}_\Theta\}_\Theta+
\{C,\{A,B\}_\Theta\}_\Theta\\
&=\<\gamma_A,\Theta\gamma_{\{B,C\}_\Theta}\>+\<\gamma_B,\Theta\gamma_{\{C,A\}_\Theta}\>+\<\gamma_C,\Theta\gamma_{\{A,B\}_\Theta}\>\\
&=\<\gamma_A,\Theta\gamma'_B[\Theta\gamma_C]\>+\<\gamma_A,\Theta T_C^T[\gamma_B]\>-\<\gamma_A,\Theta\gamma'_C[\Theta\gamma_B]\>\\
&+\<\gamma_B,\Theta\gamma'_C[\Theta\gamma_A]\>+\<\gamma_B,\Theta T_A^T[\gamma_C]\>-\<\gamma_B,\Theta\gamma'_A[\Theta\gamma_C]\>\\
&+\<\gamma_C,\Theta\gamma'_A[\Theta\gamma_B]\>+\<\gamma_C,\Theta T_B^T[\gamma_A]\>-\<\gamma_C,\Theta\gamma'_B[\Theta\gamma_A]\>\\
&=\<\gamma_A,\Theta T_C^T[\gamma_B]\>+\<\gamma_B,\Theta T_A^T[\gamma_C]\>+\<\gamma_C,\Theta T_B^T[\gamma_A]\>\\
&=-\<T_C[\Theta\gamma_A],\gamma_B\>-\cdots\\
&=-[\<\gamma_B,\Theta'[\Theta\gamma_A]\gamma_C\>+\<\gamma_C,\Theta'[\Theta\gamma_B]\gamma_A\>+\<\gamma_A,\Theta'[\Theta\gamma_C]\gamma_B\>]=0.
\end{align*}

The KdV equation has infinitely many Poisson structures.
Let
\[\Theta_1(u):=-\partial_x,\qquad\Theta_2(u):=-(\partial_x^3+4u\partial_x+2u_x),\]
and
\[\gamma_0:=\frac12,\qquad\gamma_1:=u,\qquad\gamma_2:=u_{2x}+3u^2.\]
The gradients $\gamma_i$ will define invariants
\[I_0(u):=\frac12\int u\,dx,\qquad I_1(u):=\int\frac12u^2\,dx,\qquad I_2(u):=\int(u^3-\frac12u_x^2)\,dx,\cdots.\]
They were mass$/2$, momentum, and energy.
We can check, but with a lot of computations, that $\Theta_2$ satisfies the condition (iii).
We also can check
\[\Theta_1\cdot\gamma_1=\Theta_2\cdot\gamma_0,\qquad\Theta_1\cdot\gamma_2=\Theta_2\cdot\gamma_1,\qquad,\Theta_1\cdot\gamma_3=.\]
Here, if we compute
\begin{align*}
\Theta_2\cdot\gamma_2&=-(\partial_x^3+4u\partial_x+2u_x)(u_2x+3u^2)\\
&=\cdots\\
&=-\partial_x[u_{4x}+10uu_{3x}+5u_x^2+10u^3],
\end{align*}
so we define $\gamma_3:=u_{4x}+10uu_{3x}+5u_x^2+10u^3$ such that $\partial\gamma_3/\partial t=0$ and $\Theta_2\cdot\gamma_2=\Theta_1\cdot\gamma_3$.
It defines an invariant of the KdV
\[I_3:=\frac12\int(u_{2x}^2-10uu_x^2+5u^4)\,dx,\]
which is tough to have a nice physical interpretation.
Inductively we can construct $\gamma_n$.
We want to check $\gamma_n$ is a gradient, i.e.~$\gamma_n'^T=\gamma_n'$, and it provides infinitely many invariants of the KdV equation.
In fact, $\sigma_n:=\Theta_1\cdot\gamma_n$ are all symmetry of the KdV.
For example, we can compute $\sigma_1=-u_x$ and $\sigma_2=-u_t$.

Here we show
\[I_n:=\int(u\int_0^1\gamma_n(\lambda u)\,d\lambda\,dx)\]
is an invariant, assuming $\gamma_n$ is a gradient.
Since $\partial I_n/\partial t=0$, we have $\{I_0,I_1\}_{\Theta_1}=\{I_0,I_2\}_{\Theta_1}=0$.
Also we have $\{I_0,I_0\}_{\Theta_1}=\{I_0,I_0\}_{\Theta_2}=0$.
So
\[\{I_m,I_n\}_{\Theta_1}=\<\gamma_m,\Theta_1\gamma_n\>=\<\gamma_m,\Theta_2\gamma_{n-1}\>=\{I_m,I_{n-1}\}_{\Theta_2},\]
and
\[\{I_m,I_n\}_{\Theta_2}=\<\gamma_m,\Theta_2\gamma_n\>=-\<\Theta_2\gamma_m,\gamma_n\>=-\<\Theta_1\gamma_{m+1},\gamma_n\>=\<\gamma_{m+1},\Theta\gamma_n\>=\<\gamma_{m+1},\Theta_2\gamma_{n-1}\>=\{I_{m+1},I_{n-1}\}_{\Theta_2}.\]
Therefore, for $m,n\ge1$,
\[\{I_m,I_n\}_{\Theta_2}=\cdots=\{I_{m+n-1},I_1\}_{\Theta_2}=\<\gamma_{m+n-1},\Theta_2\gamma_1\>=I'_{m+n-1}[u_t]=\frac{dI_{m+n-1}}{dt}.\]
The left-hand side is skew-symmetric, but the right-hand side is symmetric.
Therefore, $dI_n/dt=0$, and strongly, we have shown $\{I_m,I_n\}_{\Theta_1}=\{I_m,I_n\}_{\Theta_2}$=0.




\newpage
\section{Day 7: November 20}


\subsection*{KdV hierarchy}

Recall that $\sigma_n:=\Theta_1\cdot\gamma_n$.
We consider a partial differential equation $u_{t_n}:=\sigma_n(u)$ for $u=u(x,t_1,t_2,\cdots)$ with infinitely many variables.
Then, for every $n\ge0$ and $m\ge1$, we have
\[\frac{dI_n}{dt_m}=\frac{\partial I_n}{\partial t_m}+I_n'[u_{t_m}]=\<\gamma_n,u_{t_m}\>=\<\gamma_n,\Theta_1\gamma_m\>=\{I_n,I_m\}_{\Theta_1}=0.\]
Also, for every $n\ge1$ and $m\ge1$, $\sigma_n(u)$ is a symmetry of $u_{t_m}=\sigma_m(u)$, i.e.
\[\frac{\partial\sigma_n}{\partial t_m}+\sigma_n'[\sigma_m]-\sigma_m'[\sigma_n]=0+\sigma_n(u)_{t_m}-\sigma_m(u)_{t_n}=0.\]
The final equality is becaus for every Schwarz $v$ we have
\[0=\<\gamma_n,\sigma\>'[v]=\<\gamma'_n[v],\sigma_m\>+\<\gamma_n,\sigma_m'[v]\>=\<v,\gamma_n'[\sigma_m]+\sigma_m'^T[\gamma_n]\>\]
so that for any differential polynomial $\alpha$
\begin{align*}
\<\alpha,\sigma_n'[\sigma_n]-\sigma'_m[\sigma_n]\>
&=\<\alpha,\Theta_1\gamma_n'[\sigma_n]\>-\<\alpha,\Theta_1\gamma'_m[\sigma_n]\>\\
&=-\<\gamma_n'[\Theta_1\alpha],\sigma_m\>+\<\Theta_1\alpha,\gamma_m'[\sigma_n]\>\\
&=-\<\gamma_n'[\Theta_1\alpha],\sigma_m\>-\<\Theta_1\alpha,\sigma_n'^T[\gamma_n]\>\\
&=\<\Theta_1\gamma_n'[\Theta_1\alpha],\gamma_m\>-\<\sigma_n'[\Theta_1\alpha],\gamma_n\>=0.
\end{align*}
The above result holds also for other integrable systems, but the above proof makes use of a a property of $\Theta_1$.
We guess the general proof involves the introduction of three test differential polynomials $\alpha,\beta,\gamma$ and the Jacobi identity.
Now, consequently we could have shown that every equation in the KdV hierarchy shares a common family of symmetry and invariants.

If we consider the Lax pair $\psi^2$, then $\Theta_1\psi^2=4\lambda^2\Theta\psi^2$, and the asymptotic expansion
\[\psi^2=\sum_{n=1}^\infty \gamma_n(4\lambda^2)^{-n}\]
if we let the first term be $\frac12$.
Also, it is itself a gradient of a special function called the spectral parameter, because $\psi^2$ is a gradient of $\lambda^2$(?).


The Lax pair of the higher KdV equation:
\[\psi_{xx}+u\psi=\lambda^2\psi,\qquad (\psi^2)_{t_n}=-\sigma_n'[\psi^2]\quad(\psi_{t_n}=M_n\psi).\]



\newpage
\section{Day 8: December 4}

\subsection*{Sato theory}
Let
\[W_2:=\partial_x^2+a(x)\partial_x+b(x)\]
be a non-degenerate differential operator, i.e.~$\dim\ker W_2=2$.
In most cases $\tau$ function in $u=2\partial_x^2\log\tau$ is given as the Wronskian determinant.
For linearly independent solutions $f_1$ and $f_2$, since
\[\tau_x=\partial_x\left|\begin{matrix}f_1&f_1'\\f_2&f_2'\end{matrix}\right|=\left|\begin{matrix}f_1&f_1''\\f_2&f_2''\end{matrix}\right|,\]
we have
\[a(x)=-\partial_x\log\tau=-\frac{\tau_x}\tau.\]

We use the following Freeman-Nimmo notation:
\[\left|\begin{matrix}f_1&f_1'&\cdots&f_1^{N-1}\\f_2&f_2'&\cdots&f_2^{N-1}\\
\vdots&\vdots&&\vdots\\f_N&f_N'&\cdots&f_N^{N-1}\\\end{matrix}\right|=:|0\ 1\ \cdots\ (N-1)|.\]
The Freeman-Nimmo notation does not depend on the choice of $(f_i)$ up to multiplicative constnat.
For example,
\[\partial_x|0\ 1\ \cdots\ (N-1)|=|1\ 1\ 2\ \cdots\ (N-1)|+|0\ 2\ 2\ \cdots\ (N-1)|+\cdots+|0\ 1\ \cdots\ (N-2)N|=|0\ 1\ \cdots\ (N-2)\ N|.\]
Also we have $\tau=|0\ 1|$, $a=|0\ 2|/\tau=-\partial_x\log\tau$, $b=|1\ 2|/\tau$.
We cannot represent $|1\ 2|$ in terms of $\tau$ yet.

Consider the relation $\partial_y=\partial_x^2$ on $h_j(x,y,t)$ (quotient by the ideal generated by $\partial_y-\partial_x^2$) and
\[\hat W_2:=\partial_x^2+\hat a(x,y,t)\partial_x+\hat b(x,y,t),\qquad \hat W_2h_j=0\quad(j=1,2).\]
By an analogy of the division algorithm we have
\[\hat W_{2,y}+\hat W_2\partial_x^2=B_2\hat W_2+R,\]
where $B_2$ is of second order and $R$ is of first order.
We can show
\[Rh_j=B_2\hat W_2h_j+Rh_j=(\hat W_{2,y}+\hat W_2\partial_x^2)h_j=(\hat W_2h_j)_y=0\quad(j=1,2),\]
so $R=0$ because $h_j$ are linearly independent and it cannot have kernel that is more than two-dimensional.
If we write $B_2=:\partial_x^2+\alpha\partial_x+\beta$, then because
\[\hat W_{2,y}+\hat W_2\partial_x^2\equiv\hat a_y\partial_x+\hat b_y+\partial_x^4+\hat a\partial_x^3+\hat b\partial_x^2\]
and
\[B_2\hat W_2\equiv\partial_x^4+\alpha\partial_x^3+\hat a\partial_x^3+O(\partial_x^2)\]
deduce $\alpha\equiv0$ so that
\[B_2\hat W_2\equiv\partial_x^4+\hat a\partial_x^3+(2\hat a_x+\hat b+\beta)\partial_x^2+(\hat a_{2x}+2\hat b_x+\beta\hat a)\partial_x+(\hat b_{2x}+\beta\hat b).\]
Thus, $\hat W_{2,y}+\hat W_2\partial_x^2=B_2\hat W_2$ implies
\[\beta=-2\hat a_x,\qquad\hat a_y=\hat a_x+2\hat b_x+\beta\hat a,\qquad\hat b_y=\hat b_{2x}+\beta\hat b,\]
so $\hat a=-\partial_x\log\tau$ from the above implies
\[\fbox{$B_2=\partial_x^2+2\partial_x^2\log\tau$}.\]
For $\tau=|0\ 1|$, we have $\tau_{2x}=|1\ 2|+|0\ 3|$, $\tau_y=|2\ 1|+|0\ 3|$, so
\[\hat a=-\partial_x\log\tau=-\frac{\tau_x}\tau,\qquad\hat b=\frac{\tau_{2x}-\tau_y}{2\tau}.\]
Therefore, we finally have
\[\fbox{$\hat W_2=\partial_x^2-\frac{\tau_x}\tau\partial_x+\frac{\tau_{2x}-\tau_y}{2\tau}$}.\]

Similarly, if we introduce the relation $\partial_t=\partial_x^3$ on $h_j(x,y,t)$, then we have $\hat W_{2,t}+\hat W_2\partial_x^3=B_3\hat W_2$ for some $B_3$ of third order, and the consistency condition $(\hat W_{2,y})_t=(\hat W_{2,t})_y$ is equivalent to $B_{2,t}-B_{3,y}=[B_3,B_2]$.

Here we introduce
\[u(x,y,t):=\partial_x^2\log\tau=-\hat a_x,\qquad v(x,y,t):=\partial_x\partial_y\log\tau=2\hat a\hat a_x-2\hat b_x-\hat a_{2x}.\]
Then, we can compute and write
\[B_2=\partial_x^2+2u,\qquad B_3=\partial_x^3+3u\partial_x+\frac32(u_x+v),\]
and we obtain the Kadomtsev-Petviashvili equation
\[u_y=v_x,\qquad 4u_t-12uu_x-u_{3x}=3v_y.\]
There is a reduced version which cancels $v$ written as
\[4u_{xt}-(u_{2x}+6u^2)_{2x}=3u_{2y},\]
but it is just a necessary condition for the consistency condition of $B_{2,t}-B_{3,y}=[B_2,B_3]$.

If we consider the independence with respect to $y$, say $\partial_yh_j=0$ with $\tau_y=0$ so that $v=0$, and if we scale appropriately, we obtain the KdV equation, so every spectial solution of the KdV gives rise to a special solution of KP.
More precisely, if we let $u=\frac12U$ and $t=-4T$, then $B_2=\partial_x^2+U=:L$ and $B_3=\partial_x^3+\frac32U\partial_x+\frac34U_x=:M_3$.

If we consider the independence with respect to $t$, then we obtain the Boussinesq equation as the consistency condition.
\[u_y=v_x,\qquad v_y=-\frac13(u_{2x}+6u^2)_x,\]
so we have a Poisson structure
\[\mat{u\\v}_y=-\mat{0&\partial_x\\\partial_x&0}\mat{\frac13(u_{2x}+6u^2)\\-v}\]
and we obtain $I=\int(\frac23u^3-\frac16u_x^2-\frac12v^2)\,dx$.


\begin{itemize}
\item Why do we introduce $\partial_x^3=\partial_t$?
\item Why do we introduce $W_2$?
\end{itemize}

\newpage
\section{Day 9: December 11}

Fix an order $m\ge2$ and suppose an operator
\[W_m:=\sum_{j=0}^mw_j\partial_x^{m-j}\]
has an $m$-dimensional kernel, the solution space.
For $n\ge2$, by the division algorithm, there is a differential operator $B_n$ of order $n$ such that
\[\partial_{t_n}W_m+W_m\partial_x^n=B_nW_m.\]
For example, for $n=2$, since $B_2:=\partial_x^2+\alpha\partial_x+\beta$ implies
\[\partial_{t_2}W_m+W_m\partial_x^2=\partial_x^{m+2}+(w_1+\alpha)\partial_x^{m+1}+(w_2+2w_{1,x}+\alpha w_{1,x}+\beta)\partial_x^m+(\cdots)\partial_x^{m-1}\cdots+(\cdots)\partial_x^0,\]
which we can compute
\[B_2=\partial_x^2+2\partial_x^2\log|0\ \cdots\ (m-1)|=:\partial_x^2+2\partial_x^2\log\tau_m,\qquad(t_1=x,\ t_2=y,\ t_3=t),\]
and obtain non-linear differential equations $(\cdots)$ for the coefficients $w$ as follows:
\[w_j(x,t_2,\cdots)=(-1)^j\frac{|0\ 1\ \cdots\ (m-j-1)\ (m-j+1)\ \cdots\ m|}{\tau_m}.\]
The $\tau$-function is determined by the solution space $\ker W_m$ up to scalar multiplication, so it would be good to take care if the scalars are cancelled in fraction.
For example, $w_1=-\partial_x\log\tau_m$.
These $m$ equations are also obtained from the consistency condition between $B_n$, the KP hierarchy
\[(B_{n_1})_{t_{n_2}}-(B_{n_2})_{t_{n_1}}=[B_{n_2},B_{n_1}].\]
Note that an equation is just a differential polynomial.
The KP equation is obtained when $n=2$ and $m=3$.
If we define a pseudo-differential operator $W:=W_m\partial_x^{-m}$, then $W_{t_n}\partial_x^m+W\partial_x^{m+n}=B_nW\partial_x^m$, so that we can take limit $n\to\infty$ on $W_{t_n}+W\partial_x^n=B_nW$.

Suppose $W_m$ has $m$ linearly independent analytic solutions $(f_j)_{j=1}^m$.
Then,
\[\Xi_0:=(\xi_{kj}|_{x=0})=(f_{j,kx}|_{x=0}),\qquad k\ge0,\ j\in\{1,\cdots,m\},\]
is of rank $m$.
We want to consider this matrix up to equivalence by a right action of $\GL(m,\C)$.
In other words, $\Xi_0$ is an element of the \emph{Grassmann variety}, the right orbit space
\[\{\infty\times m\text{ matrices of rank }m\}/\GL(m,\C)=:\Gr(m,\infty),\]
so \textbf{$\Xi_0$ is just a representative of the solution space $\ker W_m\in\Gr(m,\infty)$}, where $W_m$ acts on $\C[[x]]$.
We have $\dim\Gr(m,n)=m(n-m)$.
For $n\ge4$, we have the first example $\Gr(2,4)$ which is not a projective space.
But it is a projective variety.
For
\[\mat{\xi_{11}&\xi_{12}\\\xi_{21}&\xi_{22}\\\xi_{31}&\xi_{32}\\\xi_{41}&\xi_{42}}|_{x=0}\in\Gr(2,4),\qquad \mu_{ij}:=\det\mat{\xi_{i1}&\xi_{i2}\\\xi_{j1}&\xi_{j2}}|_{x=0},\]
then $(\mu_{12}:\mu_{13}:\mu_{14}:\mu_{23}:\mu_{24}:\mu_{34})$ is a point of $\CP^5$.
This idea gives the Pl\"ucker embedding $\Gr(m,n)\hookrightarrow\CP^{{n\choose m}-1}$, which is extended to $\Gr(m,\infty)\hookrightarrow\CP^\infty$.
The image is generated by quadratic homogeneous polynomials(=quadratic form on $\C^{{n\choose m}}$).

Using the exponential of the shift operator $\Lambda$, we can consider
\[(\xi_{kj}):=(f_{j,kx})=e^{x\Lambda}\Xi_0.\]
Because $f_j$ are fully determined by the germ at zero, it contains the same data with $\Xi_0$.
We want to introduce $t_n$ such that $f_j(x)=h_j(x,0,\cdots)$ and $(h_j)_{t_n}=(h_j)_{nx}$.
Such functions $h_j$ can be constructed by the column vectors of
\[\Xi:=e^{\sum_{n=2}^\infty t_n\Lambda^n}e^{x\Lambda}\Xi_0.\]
This matrix can be computed by the Schur polynomials $p_n(t_1,\cdots)$, which is weighted homogeneous and satisfies $(p_n)_{t_k}=p_{n-k}$.



\newpage

\section{Day 10: December 25}
Recall
\[\Xi:=e^{\sum_{n=2}^\infty t_n\Lambda^n}e^{x\Lambda}\Xi_0.\]
The matrix $\Xi$ depends on $t_1=x,t_2,\cdots$ and it represents a infinite-dimensional flow on the Grassmann variety $\Gr(m,\infty)$.

The Schur polynomial:
\begin{align*}
p_0&=1\\
p_1&=t_1\\
p_2&=t_2+\frac12t_1^2\\
p_3&=t_3+t_1t_2+\frac16t_1^3.
\end{align*}
The matrix $\Xi$ satisfies $\Xi_{t_k}=\Xi_{kx}=\Lambda^k\Xi$.
Also,
\begin{align*}
\tau(t_1,t_2,\cdots)
&=\det\left[\mat{I_m&O}\Xi(t_1,t_2,\cdots)\right]\\
&=\det\left[\mat{I_m&O}\mat{1&p_1&p_2&\cdots\\0&1&p_1&\cdots\\0&0&1&\cdots}\Xi_0\right]\\
&=\sum_{0\le l_1<\cdots<l_m}\det\left[
\mat{p_{l_1}&p_{l_2}&\cdots&p_{l_m}\\p_{l_1-1}&p_{l_2-1}&\cdots&p_{l_m-1}\\\vdots&&&\vdots\\p_{l_1-m+1}&p_{l_2-m+1}&\cdots&p_{l_m-m+1}\\}
\mat{\xi_{l_1,1}&\xi_{l_1,2}&\cdots&\xi_{l_1,m}\\\xi_{l_2,1}&\xi_{l_2,2}&\cdots&\xi_{l_2,m}\\\vdots&\vdots&&\vdots\\\xi_{l_m,1}&\xi_{l_m,2}&\cdots&\xi_{l_m,m}\\}
\right]\\
&=:\sum_{y:\text{young diagram of $m$ rows}}\chi_y(t_1,t_2,\cdots)\xi_y,
\end{align*}
where $\chi_y$ is called the Schur functions and $\xi_y$ are Pl\"ucker coordinates which does not depend on $t_1,t_2,\cdots$.
The $\tau$-function can be considered as an element of a homogeneous coordinate ring of $\Gr(m,\infty)$.
It can be interpreted as a ``Taylor expansion'' of $\tau$ because
\[\xi_y=\chi_y(\tilde\partial)\tau(t_1,t_2,\cdots)|_{t_1=t_2=\cdots=0},\]
where
\[\tilde\partial_t:=(\partial_{t_1},\frac12\partial_{t_2},\frac13\partial_{t_3},\cdots)\]



\subsection*{Maya diagram}

For example, let $n=m=4$ and $(l_1,\cdots,l_4)=(2,3,5,7)$.
Then, the corresponding Maya diagram is
\[O\cdot O_{-m=-4}XXO_{l_1+1-m=-1}O_{l_2+1-m=0}XOXOXX\cdots\]
and the corresponding Young diagram is $(\lambda_1,\cdots,\lambda_4)=(4,3,2,2)$:
\begin{align*}
&OOOO\\
&OOO\\
&OO\\
&OO
\end{align*}
because the Maya daigram indicates the right below boundary $\to\to\uparrow\uparrow\to\uparrow\to\uparrow$.
Generally, $(l_1,\cdots,l_m)\mapsto(\lambda_1,\cdots,\lambda_m)$ is related as $l_j=\lambda_{m-j+1}+j-1$.
This is $\infty$-to-one correspondence, but if $m$ is fixed, then one-to-one.

We have facts
\[\chi_y(\tilde\partial_t)|0\ 1\ \cdots\ (m-1)|=|l_1\ l_2\ \cdots l_m|,\qquad\chi_y(\tilde\partial_t)\tau_\varnothing=\tau_y,\]
and
\[\chi_{y_1}(\tilde\partial_t)\chi_{y_2}(t)=\delta_{y_1,y_2},\qquad\chi_{y_1}(t)=(-1)^{|y_1|}\chi_{^ty_1}(-t).\]
In particular,
\[\chi_{(11)}(t)=\frac12t_1^2-t_2,\quad\chi_{(2)}(t)=t_2+\frac12t_1^2,\qquad\chi_{(11\cdots1)}(t)=(-1)^j\chi_{(j)}(-t)=(-1)^jp_j(-t),\]
and hence very happily we have
\[w_j=\frac{p_j(-\tilde\partial_t)\tau}{\tau},\qquad j=1,\cdots,m.\]

With the above computations, we can generalize $W$ to the infinite-order pseudo-differential operator by letting $m=\infty$.
In this case, we can define $\tau$ not as a determinant, but as follows:
First, $p_n(-\tilde\partial_t)\tau$ can be seen such that
\[\tau(t_1-\frac1\lambda,t_2-\frac1{2\lambda^2},t_3-\frac1{3\lambda^3},\cdots)=e^{-\sum\frac{\lambda^n}n\partial_{t_n}}\tau=\sum_{n=0}^\infty p_n(-\tilde\partial_t)\tau\lambda^n.\]
We do not have to consider infinite-dimensional matrices, because $p_n(-\tilde\partial_t)\tau\equiv0$ for $n>N$ by the pigeonhole principle.







\newpage

\section*{My own notes}

\subsection*{Differential polynomials}

\begin{prb}[Differential polynomials]
Consider a differentiable field $\R$, which has infinitely many trivial derivations $\partial_x$, $\partial_t$, and $\partial_{t_i}$ with $i=1,2,\cdots$.
Write $\R_x:=(\R,\partial_x)$ and $\R_{x,t}:=(\R,\partial_x,\partial_t)$, and write $u_{mxnt}:=\partial_x^m\partial_t^nu$ for $n,m\in\Z_{\ge0}$ and an indeterminate $u$.
Then, we have commutative non-trivial differential algebras
\[\R_x\{u\}=\R[u,u_x,u_{2x},\cdots],\qquad\R_{x,t}\{u\}=\R[u,u_x,u_t,u_{2x},u_{xt}\cdots].\]
Their elements are called \emph{differential polynomials}, but it usually will be the elements of $\R_x\{u\}$.

Let $\kappa\in\R_x\{u\}$ be a differential polynomial.
For example, consider a differential polynomial $\kappa(u)=-u_{3x}-6uu_x$, which is called the \emph{KdV equation}.
The image of the indeterminate $u\in\R_{x,t}\{u\}$ in the quotient $\R_{x,t}\{u\}/(u_t-\kappa(u))$ is called the \emph{solution} of $\kappa$, where $(u_t-\kappa(u))$ is the differential ideal generated by $u_t-\kappa(u)\in\R_{x,t}\{u\}$.
\end{prb}

\begin{prb}[Differential operator algebra]
Note that the formal polynomial ring $\R_x\{u\}[\partial_x]$ has a noncommutative associative algebra structure determined by the relation
\[\partial_xu=u_x+u\partial_x.\]
An element $T$ of $\R_x\{u\}[\partial_x]$ is usually called an \emph{operator}, indeed, it can define a linear operator $\R_x\{u\}\to\R_x\{u\}:\alpha\mapsto T[\alpha]$.
\[\R_x\{u\}[\partial_x]\hookrightarrow\End(\R_x\{u\}).\]
The Weyl algebra can be obtained as the quotient of $\R_x\{u\}[\partial_x]$ by $u_x-1$.
\end{prb}

\begin{prb}[Fr\'echet derivatives]
For a differential polynomial $\alpha\in\R_x\{u\}$, we can define a differential operator
\[\alpha'\in\R_x\{u\}[\partial_x]\subset\End_\R(\R_x\{u\}),\] and a $\R_x\{u\}$-valued symmetric bilinear form
\[\alpha''\in\Hom_\R(\R_x\{u\}\times\R_x\{u\},\R_x\{u\})\]
such that
\[\alpha(u+\e\beta(u))=\alpha(u)+\e\alpha'(u)[\beta(u)]+\frac{\e^2}2\alpha''(u)[\beta(u),\beta(u)]+O(\e^3),\qquad\e\to0.\]

\[(u_{mx})':=\partial_x^m,\quad(\alpha\beta)':=\beta\alpha'+\alpha\beta'.\]
\begin{parts}
\item $(\alpha'[\beta])'[\gamma]=\alpha''[\beta,\gamma]+\alpha'[\beta'[\gamma]]$.
\item $[\alpha,\beta]:=\alpha'[\beta]-\beta'[\alpha]$ defines a Lie bracket on $\R_x\{u\}$.
\end{parts}
\end{prb}


\subsection*{Lax pairs}

\begin{prb}[Lax pair]
Fix a differential polynomial $\kappa\in\R_x\{u\}$.
A pair $(L,M)$ of operators is a said to be a \emph{Lax representation} of $\kappa$ if $\kappa=[M,L]$, where $[M,L]:=ML-LM$ is the commutator.
\begin{parts}
\item If $L[u]:=\partial^2+u$ and $M[u]:=-4\partial^3-6u\partial-3u_x$, then $(L,M)$ is a Lax representation of the KdV equation $\kappa(u)=-u_{3x}-6uu_x$.
\end{parts}
\end{prb}


\begin{prb}[Inverse scattering transform]

\end{prb}



\subsection*{Invariants}
\begin{prb}[Inner products]
\emph{transpose} of an operator $\R_x\{u\}[\partial_x]\to\R_x\{u\}[\partial_x]$.
\end{prb}

\begin{prb}[Invariants]
A differential polynomial $\rho\in\R_x\{u\}$ is said to define an \emph{invariant} for $\kappa$ if there is a differential polynomial $\alpha$ such that $\partial_t\rho=\partial_x\alpha$ in $\R_{x,t}\{u\}/(u_t-\kappa(u))$.
\end{prb}

\begin{prb}[Symmetry]
We say $\sigma\in\R_x\{u\}$ is a \emph{symmetry} of $\kappa\in\R_x\{u\}$ if $\partial_t\sigma=\kappa'[\sigma]-\sigma'[\kappa]$ in $\R_{x,t}\{u\}/(u_t-\kappa(u))$.
\end{prb}

\begin{prb}[Lagrangian]
Let $\lambda$ be a differential polynomial.
\end{prb}


\begin{prb}[Poisson structure]
A \emph{Poisson structure} is an operator $\Theta\in\R_x\{u\}[\partial_x]$ which is skew-symmetric and satisfies a...
\end{prb}


\subsection*{Solita}

tau-function, hirota bilinear
sato theory

\[W\in\R_{x,y,t}\{u\}[\partial_x]\]

Intuitively on the space spanned by $h_j$, introducing the free variables $t_n$ for $n\ge2$ means the quotient
\[\R_{x,t_n}\{u\}/(u_t-u_{nx}).\]



\subsection*{Affine Lie algebras}

nonlinear integrable system can be understood as deformations of D-modules
Y-systems










\end{document}