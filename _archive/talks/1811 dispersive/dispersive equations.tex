\documentclass{../exp}
\usepackage{../../ikany}

\title{Dispersive equations}

\begin{document}
\maketitle



\section{Introduction}

In this article, the purpose is on proving a dispersive inequality for solutions of an initial value problem of the Sch\"odinger equation for no potential
\begin{pde}{\label{eq:Schrod}}
i\pd_tu+\Delta u&=0, \: \text{ in }\R_t\x\R_x^d,\\
u(0,x)&=u_0(x). \:
\end{pde}

The statemaent of our dispersive inequality is given as follows.
\begin{thm}[Dispersive estimate]
Let $u$ be a solution of (\ref{eq:Schrod}).
Then,
\[\|u(t,x)\|_{L^\infty(\R_x^d)}\les_dt^{-\frac d2}\|u(0,x)\|_{L^1(\R_x^d)}.\]
\end{thm}
We can observe the inequality implies that the solution decays as time flows.



\section{What is dispersion?}
\subsection{Optics}
In optics, the \emph{dispersion} is the phenomenon that the index of refracion depends on the wavelength.

A dispersion relation of light in transparent material is given by the Cauchy formula, an approximate empirical equation,
\[n(\lambda)=B+\frac C{\lambda^2}.\]

For exmaples, 


\subsection{Quantization}
We can make a PDE form a dispersion relation by quantization.
Mathematically, we can simply define a ``wave'' as a superposition of complex exponential functions on timespace $\R^{1+d}$ that have the form
\[\psi(t,x)=e^{i(k\cdot x-\omega t)},\]
where the parameters $\omega\in\R$ and $k\in\R^d$ are related by dispersion relation.
On the space of wave functions, the multiplication operators with respect to $\omega$ and $k$ are same with partial differential operators on wave functions:
\[i\pd_t\psi=\omega\psi,\quad -i\pd_{x_i}\psi=k_i\psi\quad(1\le i\le d).\]

Consider the Schr\"odinger equation as an example.
The energy conservation
\[E=\frac{p^2}{2m}+V\]
and the de Broglie relation
\[E=\hbar\omega,\quad p=\hbar k\]
give the dispersion relation
\[\hbar\omega=\frac{|\hbar k|^2}{2m}+V,\]
which is in fact the Schr\"odinger equation
\[i\hbar\pd_t=-\frac{\hbar^2}{2m}\Delta+V.\]

\subsection{Dispersive equation}
\begin{defn}
If the dispersive relation is not of the form $\omega(k)\propto|k|$, the wave is called dispersive.
\end{defn}



\section{Method I: representation formula}

\subsection{Basics on Fourier transform}





\subsection{Multiplier}



\begin{defn}
The \emph{time evolution operator} is the multiplier operator associated with $e^{-iHt}$, and is denoted by $e^{-i\Delta t}$:
\[\hat{e^{-i\Delta t}u}(x):=e^{-iHt}\hat u(k)\]
\end{defn}
\begin{defn}
The \emph{propagator} is inverse transform of $e^{-iHt}$, and is denoted by $K(x;t)$.
\end{defn}
\[\hat{e^{-i\Delta t}u}=e^{-iHt}\hat u=\hat{K*u}.\]


% convolution : D' x D -> D' 가 잘 정의되는가?
% 
\subsection{Fundamental solution}
First,
\[P(D)K(t,x)=0,\quad t>0\]
implies
\begin{align*}
i\pd_tK+\Delta_xK&=0\\
i\pd_t\hat{K}-|k|^2\hat{K}&=0\\
\pd_t(\log\hat{K})&=-i|k|^2\\
\hat{K}(t,k)&=C(k)e^{-i|k|^2t}.
\end{align*}
And then,
\[K(0,x)=\delta(x),\quad t=0\]
implies
\[\hat{K}(t,k)=e^{-i|k|^2t}.\]

Differentiaing,
\begin{align*}
\nabla_k\hat{K}&=-i2kt\hat{K}\\
xK&=-i2t\nabla_xK\\
\nabla_x(\log K)&=i\frac x{2t}\\
K(t,x)&=C(t)e^{i\frac{|x|^2}{4t}}.
\end{align*}
Since
\[C(t)=K(t,0)=\int e^{-i|k|^2t}\,dk=(\pi it)^{-\frac d2},\]
we get
\[K(t,x)=(\pi it)^{-\frac d2}e^{i\frac{|x|^2}{4t}}.\]

\section{Method II: oscillatory integral}
\subsection{Reducing problem}

By Fourier transform, we get an ODE
\[i\pd_t\hat u(t,k)+|k|^2\hat u(t,k)=0,\]
solved by
\[\hat u(t,k)=\hat u_0(k)e^{-i|k|^2t}.\]
Taking inverse Fourier transform, the solution of the original equation is given by
\[u(t,x)=\int\hat u_0(k)e^{i(k\cdot x-|k|^2t)}\,dk.\]

Define phase
\[\Phi(t,x,k):=k\cdot x-|k|^2t\]
and an oscillatory integral
\[I(t,x):=\int\hat u_0(k)e^{i\Phi}\,dk,\]
which is exactly the same with the general solution.

The statemaent of our dispersive inequality is given as follows.
\begin{thm}[Dispersive estimate]
We have an asymptotic inequality
\[\sup_x|I(t,x)|\lesssim t^{-\frac d2}\]
for $t\gtrsim1$.
\end{thm}
We can observe the inequality implies that the solution decays as time flows.

To prove this, we are going to make pointwise estimates for $I$.


To begin with, fix $x$.
Note that the equation (\ref{eq:Schrod}) has a rotational symmetry on physical space.
Thus we assume $x_2=\cdots=x_d=0$.
Also, suppose the support of $a(\xi)$ is restricted to an annulus $\frac12<|\xi|<2$.
This assumption is valid because a simple dyadic decomposition guarantees the generality.




\subsection{Stationary and nonstationary phases}
\begin{defn}
Let $\Phi$ be the phase defined as above.
A \emph{stationary} point $\xi^o(t,x)$ is a point at which $\nabla_\xi\Phi$ vanishes.
\end{defn}
The word ``stationary'' is not with respect to time flows, but change of $\xi$.
I think it would be fantastic if here is a 3d image to explain how the principles of stationary and nonstationary phase work.


The idea is to divide the oscillatory integral.
\[I=I_{stat}+I_{nonstat}.\]
We have $height\x base\sim base$ for $I_{stat}$, and cancellation for $I_{nonstat}$.
If one has a nice estimate, then the other must be bigger.
Therefore, a natural question comes up with: how can we choose the suitable boundary to get an optimal estimate?
Here, what we are going to use is a heuristic technique called ``Linearizing phase''.
In fact, it is not a linearization but a \emph{Taylorization}, but never mind.
By the technique, we can expect to read out a suitable estimate: this is exactly $-\frac d2$, which is mentioned at the statement of our theorem.
Proof will begin after getting $-\frac d2$.

Let us give a toy example to catch the idea.
\begin{ex}[Fresnel type integral]
Let
\[I(\lambda)=\int a(\xi)e^{i\lambda\xi^n}\,d\xi\]
and $\Phi(\lambda,\xi)=\lambda\xi^n$.
In this problem, $\lambda$ plays a similar role with $t$.

\end{ex}

\subsection{Heuristic method by linearizing phase}
At first, the stationary point $\xi^o$ is computed as
\[\xi_1^o=\left(\frac{|x_1|}{\alpha t}\right)^{\frac1{\alpha-1}},\qquad\xi_2^o=\cdots=\xi_d^o=0.\]
Note $|\xi^o|=\xi_1^o$.
Although $\xi^o$ depends on $t$, since the amplitude function $a(\xi)$ is supported on $\frac12<|\xi|$, we can let $|\xi^o|$ as a constant asymptotically.
Let $\xi'=\xi-\xi^o$ be an auxiliary variable for localization at $\xi^o$.

Intuitively, if $|\Phi(\xi)-\Phi(\xi^o)|$ is greater than $2\pi$, then $\xi$ belongs to the region of nonstationary.
Thus, our plan is to find the region $\{|\xi'|:|\Phi(\xi)-\Phi(\xi^o)|\lesssim1\}$ since $2\pi$ is same with 1.
Apply the Taylor expansion.
Since
\[\pd_{\xi_i}\pd_{\xi_j}\Phi(\xi)=\alpha|\xi|^{\alpha-2}t(\delta_{ij}+(\alpha-2)\frac{\xi_i}{|\xi|}\frac{\xi_j}{|\xi|},\]
we have
\[\Hess_{\xi^o}[\Phi]=\begin{pmatrix}\alpha(\alpha-1)|\xi^o|^{\alpha-2}t&0\\0&\alpha|\xi^o|^{\alpha-2}t\cdot\id_{d-1}\end{pmatrix}.\]
Therefore, by the Taylor expansion,
\begin{align*}
1&\gtrsim|\Phi(\xi)-\Phi(\xi^o)|\\
&\sim|\Hess_{\xi^o}[\Phi](\xi',\xi')|\\
&\sim\alpha|\xi^o|^{\alpha-2}t[(\alpha-1)|\xi'_1|^2+|\xi'_2|^2+\cdots+|\xi'_d|^2]\\
&\sim t|\xi'|^2.
\end{align*}
This lets us know the desired boundary $|\xi'|\lesssim t^{-\frac12}$: say, $I_{stat}\sim\int\chi_{|\xi'|<t^{-1/2}}(\xi')a(\xi)e^{i\Phi}\,d\xi$.

\subsection{Dyadic decomposition}
This section begins the real proof.
The stationary part is a piece of cake: since the area of base is aymptotically $d$-power of the radius $t^{-\frac12}$,
\[|I_{stat}\lesssim 1\x t^{-\frac d2}=t^{-\frac d2}.\]
Now, what we have to do is to show $|I_{nonstat}|\lesssim t^{-\frac d2}$.

Both the height and the volume of the base are roughly 1 on the nonstationary region $|\xi'|$, we need to do something genius.
The height cannot be reduced under 1, so we are going to decompose the supports of the amplitude $a$: take a partition of unity
\[\chi_{<1}(\xi')=\chi_{<t^{-1/2}}(\xi')+\sum_{\substack{t^{-1/2}<\mu t^{-1/2}\le1\\ \log_2\mu\in\Z}}\chi_{\mu t^{-1/2}}(\xi'),\]
where $\chi_{<k}(\xi')$ and $\chi_k(\xi')$ are smooth functions supported on $|\xi'|<2k$ and $\frac12k<|\xi'|<2k$ respectively.
If we define
\[I_\mu:=\int\chi_{\mu t^{-1/2}}(\xi')a(\xi)e^{i\Phi}\,d\xi,\]
then we have
\begin{align*}
I&=\int a(\xi)e^{i\Phi}\,d\xi\\
&=\int\chi_{<1}(\xi')a(\xi)e^{i\Phi}\,d\xi\\
&=\int\chi_{<t^{-1/2}}(\xi')a(\xi)e^{i\Phi}\,d\xi+\sum_{\substack{t^{-1/2}<\mu t^{-1/2}\le1\\ \log_2\mu\in\Z}}I_\mu\\
&=I_{stat}+I_{nonstat}.
\end{align*}
Notice that $|\xi'|\sim\mu t^{-1/2}$ $\Leftrightarrow$ $t^{-1}|\xi'|^{-2}\sim\mu^{-2}$ and the base gets reduced to $(\mu t^{-1/2})^d\sim t^{-\frac d2}$.
This is a reason why the dyadic decomposition is useful.
For some reasons that will be seen, dyadic decomposition becomes a powerful tool to estimate an oscillatory integral for polynomial phase.
However, even though the sum in $I_{nonstat}$ is finite, the number of $\mu$'s that are summed is dependent on $t$, so we want to get rid of such dependency by summing up with a constant bound, which is impossible as of now since $\mu=2,4,8,16,\cdots$ and $d>0$.
In this situation, we can compress the size of $\mu^d$ by the \emph{repeated integral by parts}.
The power of magic number $t^{-\frac12}$ arises in this procedure.








\end{document}

1.intro
2.dispersion
3.explicit formula
evolution operator
propagator
fundamental solution


4.oscillatory integral:
 stationary/nonstationary phase
 heuristic method
 dyadic decomposition
























